{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Preprocessing with SKLearn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                                   Moran, Mr. James    male   NaN      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            330877   8.4583   NaN        Q  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "data = pd.read_csv(\"Titanic_0.csv\"))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `titanic` dataset contains both categorical, text, and numeric features. We will use this dataset to predict whether a passenger survived the Titanic or not. \n",
    "\n",
    "Let's split the data into training and testing sets and use the `Survived` column as a target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Survived']\n",
    "X = data.drop(columns='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            141\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          549\n",
       "Embarked         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            108\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          411\n",
       "Embarked         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['S', 'C', 'Q', nan], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.Embarked.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>589</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>595</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>659</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>643</td>\n",
       "      <td>male</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>249</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>664</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>534 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sex Embarked\n",
       "116    male        S\n",
       "131    male        S\n",
       "589  female        S\n",
       "27     male        S\n",
       "595    male        S\n",
       "..      ...      ...\n",
       "659  female        S\n",
       "256    male        S\n",
       "643    male        C\n",
       "249  female        C\n",
       "664  female        C\n",
       "\n",
       "[534 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[['Sex', 'Embarked']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the classifiers are designed to work with numerical data. Therefore, we need to convert the categorical data into numeric features. The simplest way is to one-hot encode each categorical feature with the `OneHotEncoder`. Let's give an example for the `Sex` and `Embarked` columns. Note that we also encounter some data which are missing. We will use a `SimpleImputer` to replace the missing values with a constant values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 1., 1., 0., 0., 0.],\n",
       "       [1., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "ohe = make_pipeline(SimpleImputer(strategy='constant'), OneHotEncoder())\n",
    "X_encoded = ohe.fit_transform(X_train[['Sex', 'Embarked']])\n",
    "X_encoded.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<534x6 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1068 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way, it is possible to encode the categorical features. However, we also want to standardize the numerical features. Thus, we need to split the original data into 2 subgroups and apply a different preprocessing: (i) one-hot encoding for the categorical data and (ii) standard scaling for the numerical data. We also need to handle missing values in both cases. For the categorical column, we replace the missing values by the string `'missing_values'` which will be interpreted as a category on its own. For the numerical data, we will replace the missing data by the mean values of the feature of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_cat = ['Sex', 'Embarked']\n",
    "col_num = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "\n",
    "X_train_cat = X_train[col_cat]\n",
    "X_train_num = X_train[col_num]\n",
    "X_test_cat = X_test[col_cat]\n",
    "X_test_num = X_test[col_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_cat = make_pipeline(SimpleImputer(strategy='constant'), OneHotEncoder())\n",
    "X_train_cat_enc = scaler_cat.fit_transform(X_train_cat)\n",
    "X_test_cat_enc = scaler_cat.transform(X_test_cat)\n",
    "\n",
    "scaler_num = make_pipeline(SimpleImputer(strategy='mean'), StandardScaler())\n",
    "X_train_num_scaled = scaler_num.fit_transform(X_train_num)\n",
    "X_test_num_scaled = scaler_num.transform(X_test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<534x6 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1068 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cat_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.84978858,  0.42402614,  0.65645945,  0.06750954],\n",
       "       [-1.00181375, -0.48169369, -0.45639562, -0.46804832],\n",
       "       [ 1.35457638,  0.42402614,  2.88216959,  0.02222428],\n",
       "       ...,\n",
       "       [-2.26210241, -0.48169369,  0.65645945, -0.47082836],\n",
       "       [-0.92580117,  1.32974597,  1.76931452,  4.36960987],\n",
       "       [-1.15383892,  0.42402614, -0.45639562, -0.35761519]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_num_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_num_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<534x4 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2028 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "sparse.csr_matrix(X_train_num_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should apply these transformations on the training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "X_train_scaled = sparse.hstack((X_train_cat_enc, sparse.csr_matrix(X_train_num_scaled)))\n",
    "X_test_scaled = sparse.hstack((X_test_cat_enc, sparse.csr_matrix(X_test_num_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `sparse.hstack():`  Stack sparse-matrices horizontally, Adding them beside each other(column wise)\n",
    "\n",
    ">h means horizontal\n",
    "\n",
    "### `sparse.vstack():`  Stack sparse-matrices vertically, Adding them on top of each other(row wise)\n",
    "\n",
    ">v means vertical\n",
    "\n",
    "### `sparse.csr_matrix():` Compressed Sparse Row matrix\n",
    "\n",
    "> These are Scipi matrices instead of Numpy, they're faster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the transformation is done, we can combine the informations which are all numerical now. Finally, we use our `LogisticRegression` classifier as a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the LogisticRegression is 0.74\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs')\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "accuracy = clf.score(X_test_scaled, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(clf.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above pattern of first transforming the data and then fitting/scoring the classifier is exactly the one we saw before. Therefore, we would like to use a pipeline for such purpose. However, we would also like to have different processing on different columns of our matrix. The `ColumnTransformer` transformer or the `make_column_transformer` function should be used. It is used to automatically apply different pipeline on different columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the Pipeline is 0.74\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "col_cat = ['Sex', 'Embarked']\n",
    "col_num = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "\n",
    "pipe_cat = make_pipeline(SimpleImputer(strategy='constant'), OneHotEncoder(handle_unknown='ignore'))\n",
    "pipe_num = make_pipeline(SimpleImputer(), StandardScaler())\n",
    "\n",
    "preprocessor = make_column_transformer((pipe_cat, col_cat), (pipe_num, col_num))\n",
    "\n",
    "pipe = make_pipeline(preprocessor, LogisticRegression(solver='lbfgs'))\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "accuracy = pipe.score(X_test, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(pipe.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>708</td>\n",
       "      <td>709</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rice, Mrs. William (Margaret Norton)</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>382652</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>709</td>\n",
       "      <td>710</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>711</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>711</td>\n",
       "      <td>712</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>712</td>\n",
       "      <td>713</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>713 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "708          709         0       3   \n",
       "709          710         0       2   \n",
       "710          711         1       1   \n",
       "711          712         0       3   \n",
       "712          713         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                                     Moran, Mr. James    male   NaN      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "708               Rice, Mrs. William (Margaret Norton)  female  39.0      0   \n",
       "709                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "710                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "711           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "712                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            330877   8.4583   NaN        Q  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "708      5            382652  29.1250   NaN        Q  \n",
       "709      0            211536  13.0000   NaN        S  \n",
       "710      0            112053  30.0000   B42        S  \n",
       "711      2        W./C. 6607  23.4500   NaN        S  \n",
       "712      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[713 rows x 12 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] . (step 1 of 2) Processing columntransformer, total=   0.0s\n",
      "[Pipeline] .... (step 2 of 2) Processing lgbmclassifier, total=   0.1s\n",
      "Accuracy score of the Pipeline is 0.79\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, KBinsDiscretizer, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "\n",
    "# We create the preprocessing pipelines for both numeric and categorical data.\n",
    "numeric_features = ['SibSp', 'Parch', 'Fare']\n",
    "categorical_features = ['Embarked', 'Sex', 'Pclass',]\n",
    "age_feaututre = ['Age']\n",
    "\n",
    "numeric_transformer = make_pipeline( SimpleImputer(strategy='mean'), StandardScaler(), PolynomialFeatures(degree = 3) ) \n",
    "categorical_transformer = make_pipeline( SimpleImputer(strategy='most_frequent'), OneHotEncoder(handle_unknown='ignore') )\n",
    "age_transformer =  make_pipeline( SimpleImputer(strategy='mean'), KBinsDiscretizer(strategy = 'uniform') ) \n",
    "\n",
    "preprocessor = make_column_transformer( \n",
    "        ( numeric_transformer, numeric_features),\n",
    "        ( categorical_transformer, categorical_features),\n",
    "        ( age_transformer, age_feaututre)\n",
    "        )\n",
    "                                        \n",
    "pipelgbm = make_pipeline( preprocessor, LGBMClassifier() , verbose = 1) \n",
    "pipelgbm.fit(X_train, y_train)\n",
    "accuracy = pipelgbm.score(X_test, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(pipe.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides, it can also be used in another pipeline. Thus, we will be able to use all `scikit-learn` utilities as `cross_validate` or `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('columntransformer',\n",
       "   ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "                     transformer_weights=None,\n",
       "                     transformers=[('pipeline-1',\n",
       "                                    Pipeline(memory=None,\n",
       "                                             steps=[('simpleimputer',\n",
       "                                                     SimpleImputer(add_indicator=False,\n",
       "                                                                   copy=True,\n",
       "                                                                   fill_value=None,\n",
       "                                                                   missing_values=nan,\n",
       "                                                                   strategy='constant',\n",
       "                                                                   verbose=0)),\n",
       "                                                    ('onehotencoder',\n",
       "                                                     OneHotEncoder(categories='auto',\n",
       "                                                                   drop=None,\n",
       "                                                                   dtype=<class 'n...\n",
       "                                                                   sparse=True))],\n",
       "                                             verbose=False),\n",
       "                                    ['Sex', 'Embarked']),\n",
       "                                   ('pipeline-2',\n",
       "                                    Pipeline(memory=None,\n",
       "                                             steps=[('simpleimputer',\n",
       "                                                     SimpleImputer(add_indicator=False,\n",
       "                                                                   copy=True,\n",
       "                                                                   fill_value=None,\n",
       "                                                                   missing_values=nan,\n",
       "                                                                   strategy='mean',\n",
       "                                                                   verbose=0)),\n",
       "                                                    ('standardscaler',\n",
       "                                                     StandardScaler(copy=True,\n",
       "                                                                    with_mean=True,\n",
       "                                                                    with_std=True))],\n",
       "                                             verbose=False),\n",
       "                                    ['Age', 'SibSp', 'Parch', 'Fare'])],\n",
       "                     verbose=False)),\n",
       "  ('logisticregression',\n",
       "   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                      intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                      multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                      random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                      warm_start=False))],\n",
       " 'verbose': False,\n",
       " 'columntransformer': ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "                   transformer_weights=None,\n",
       "                   transformers=[('pipeline-1',\n",
       "                                  Pipeline(memory=None,\n",
       "                                           steps=[('simpleimputer',\n",
       "                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                 copy=True,\n",
       "                                                                 fill_value=None,\n",
       "                                                                 missing_values=nan,\n",
       "                                                                 strategy='constant',\n",
       "                                                                 verbose=0)),\n",
       "                                                  ('onehotencoder',\n",
       "                                                   OneHotEncoder(categories='auto',\n",
       "                                                                 drop=None,\n",
       "                                                                 dtype=<class 'n...\n",
       "                                                                 sparse=True))],\n",
       "                                           verbose=False),\n",
       "                                  ['Sex', 'Embarked']),\n",
       "                                 ('pipeline-2',\n",
       "                                  Pipeline(memory=None,\n",
       "                                           steps=[('simpleimputer',\n",
       "                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                 copy=True,\n",
       "                                                                 fill_value=None,\n",
       "                                                                 missing_values=nan,\n",
       "                                                                 strategy='mean',\n",
       "                                                                 verbose=0)),\n",
       "                                                  ('standardscaler',\n",
       "                                                   StandardScaler(copy=True,\n",
       "                                                                  with_mean=True,\n",
       "                                                                  with_std=True))],\n",
       "                                           verbose=False),\n",
       "                                  ['Age', 'SibSp', 'Parch', 'Fare'])],\n",
       "                   verbose=False),\n",
       " 'logisticregression': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                    intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                    multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                    random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                    warm_start=False),\n",
       " 'columntransformer__n_jobs': None,\n",
       " 'columntransformer__remainder': 'drop',\n",
       " 'columntransformer__sparse_threshold': 0.3,\n",
       " 'columntransformer__transformer_weights': None,\n",
       " 'columntransformer__transformers': [('pipeline-1', Pipeline(memory=None,\n",
       "            steps=[('simpleimputer',\n",
       "                    SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "                                  missing_values=nan, strategy='constant',\n",
       "                                  verbose=0)),\n",
       "                   ('onehotencoder',\n",
       "                    OneHotEncoder(categories='auto', drop=None,\n",
       "                                  dtype=<class 'numpy.float64'>,\n",
       "                                  handle_unknown='ignore', sparse=True))],\n",
       "            verbose=False), ['Sex', 'Embarked']),\n",
       "  ('pipeline-2', Pipeline(memory=None,\n",
       "            steps=[('simpleimputer',\n",
       "                    SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "                                  missing_values=nan, strategy='mean',\n",
       "                                  verbose=0)),\n",
       "                   ('standardscaler',\n",
       "                    StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       "            verbose=False), ['Age', 'SibSp', 'Parch', 'Fare'])],\n",
       " 'columntransformer__verbose': False,\n",
       " 'columntransformer__pipeline-1': Pipeline(memory=None,\n",
       "          steps=[('simpleimputer',\n",
       "                  SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "                                missing_values=nan, strategy='constant',\n",
       "                                verbose=0)),\n",
       "                 ('onehotencoder',\n",
       "                  OneHotEncoder(categories='auto', drop=None,\n",
       "                                dtype=<class 'numpy.float64'>,\n",
       "                                handle_unknown='ignore', sparse=True))],\n",
       "          verbose=False),\n",
       " 'columntransformer__pipeline-2': Pipeline(memory=None,\n",
       "          steps=[('simpleimputer',\n",
       "                  SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "                                missing_values=nan, strategy='mean',\n",
       "                                verbose=0)),\n",
       "                 ('standardscaler',\n",
       "                  StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       "          verbose=False),\n",
       " 'columntransformer__pipeline-1__memory': None,\n",
       " 'columntransformer__pipeline-1__steps': [('simpleimputer',\n",
       "   SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "                 missing_values=nan, strategy='constant', verbose=0)),\n",
       "  ('onehotencoder',\n",
       "   OneHotEncoder(categories='auto', drop=None, dtype=<class 'numpy.float64'>,\n",
       "                 handle_unknown='ignore', sparse=True))],\n",
       " 'columntransformer__pipeline-1__verbose': False,\n",
       " 'columntransformer__pipeline-1__simpleimputer': SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "               missing_values=nan, strategy='constant', verbose=0),\n",
       " 'columntransformer__pipeline-1__onehotencoder': OneHotEncoder(categories='auto', drop=None, dtype=<class 'numpy.float64'>,\n",
       "               handle_unknown='ignore', sparse=True),\n",
       " 'columntransformer__pipeline-1__simpleimputer__add_indicator': False,\n",
       " 'columntransformer__pipeline-1__simpleimputer__copy': True,\n",
       " 'columntransformer__pipeline-1__simpleimputer__fill_value': None,\n",
       " 'columntransformer__pipeline-1__simpleimputer__missing_values': nan,\n",
       " 'columntransformer__pipeline-1__simpleimputer__strategy': 'constant',\n",
       " 'columntransformer__pipeline-1__simpleimputer__verbose': 0,\n",
       " 'columntransformer__pipeline-1__onehotencoder__categories': 'auto',\n",
       " 'columntransformer__pipeline-1__onehotencoder__drop': None,\n",
       " 'columntransformer__pipeline-1__onehotencoder__dtype': numpy.float64,\n",
       " 'columntransformer__pipeline-1__onehotencoder__handle_unknown': 'ignore',\n",
       " 'columntransformer__pipeline-1__onehotencoder__sparse': True,\n",
       " 'columntransformer__pipeline-2__memory': None,\n",
       " 'columntransformer__pipeline-2__steps': [('simpleimputer',\n",
       "   SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "                 missing_values=nan, strategy='mean', verbose=0)),\n",
       "  ('standardscaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       " 'columntransformer__pipeline-2__verbose': False,\n",
       " 'columntransformer__pipeline-2__simpleimputer': SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "               missing_values=nan, strategy='mean', verbose=0),\n",
       " 'columntransformer__pipeline-2__standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'columntransformer__pipeline-2__simpleimputer__add_indicator': False,\n",
       " 'columntransformer__pipeline-2__simpleimputer__copy': True,\n",
       " 'columntransformer__pipeline-2__simpleimputer__fill_value': None,\n",
       " 'columntransformer__pipeline-2__simpleimputer__missing_values': nan,\n",
       " 'columntransformer__pipeline-2__simpleimputer__strategy': 'mean',\n",
       " 'columntransformer__pipeline-2__simpleimputer__verbose': 0,\n",
       " 'columntransformer__pipeline-2__standardscaler__copy': True,\n",
       " 'columntransformer__pipeline-2__standardscaler__with_mean': True,\n",
       " 'columntransformer__pipeline-2__standardscaler__with_std': True,\n",
       " 'logisticregression__C': 1.0,\n",
       " 'logisticregression__class_weight': None,\n",
       " 'logisticregression__dual': False,\n",
       " 'logisticregression__fit_intercept': True,\n",
       " 'logisticregression__intercept_scaling': 1,\n",
       " 'logisticregression__l1_ratio': None,\n",
       " 'logisticregression__max_iter': 100,\n",
       " 'logisticregression__multi_class': 'auto',\n",
       " 'logisticregression__n_jobs': None,\n",
       " 'logisticregression__penalty': 'l2',\n",
       " 'logisticregression__random_state': None,\n",
       " 'logisticregression__solver': 'lbfgs',\n",
       " 'logisticregression__tol': 0.0001,\n",
       " 'logisticregression__verbose': 0,\n",
       " 'logisticregression__warm_start': False}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1444b0aa5c8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler,  RobustScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipe_cat = make_pipeline(SimpleImputer(strategy='constant'), OneHotEncoder(handle_unknown='ignore'))\n",
    "pipe_num = make_pipeline(StandardScaler(), SimpleImputer())\n",
    "\n",
    "preprocessor = make_column_transformer((pipe_cat, col_cat), (pipe_num, col_num))\n",
    "\n",
    "pipe = make_pipeline(preprocessor, LogisticRegression(solver='lbfgs'))\n",
    "\n",
    "param_grid = {'columntransformer__pipeline-2__simpleimputer__strategy': ['mean', 'median'],\n",
    "              'logisticregression__C': [0.1, 1.0, 10],\n",
    "              'columntransformer__pipeline-2__standardscaler' : [MinMaxScaler(), RobustScaler() ] }\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "scores = pd.DataFrame(cross_validate(grid, X, y, scoring='balanced_accuracy', cv=5, n_jobs=-1, return_train_score=True))\n",
    "scores[['train_score', 'test_score']].boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### columntransformer__:\n",
    "\n",
    "- inside columntransformner\n",
    "\n",
    "### pipeline-2:\n",
    "- means second pipeline (pipe_num)\n",
    "\n",
    "### simpleimputer:\n",
    "\n",
    "- simpleimputer of the second pipeline\n",
    "\n",
    "### strategy:\n",
    "\n",
    "- set the strategy for the simpleiputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced accuracy:\n",
    "    \n",
    "- is calculated as the average of the proportion corrects of each class individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.756175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.780682</td>\n",
       "      <td>0.780989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.772797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.786364</td>\n",
       "      <td>0.783830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.849962</td>\n",
       "      <td>0.005984</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.783504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.794112</td>\n",
       "      <td>0.005985</td>\n",
       "      <td>0.752315</td>\n",
       "      <td>0.790823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.828635</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.783670</td>\n",
       "      <td>0.778850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  1.756175    0.000000    0.780682     0.780989\n",
       "1  1.772797    0.000000    0.786364     0.783830\n",
       "2  1.849962    0.005984    0.772727     0.783504\n",
       "3  1.794112    0.005985    0.752315     0.790823\n",
       "4  1.828635    0.000000    0.783670     0.778850"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'columntransformer__pipeline-2__simpleimputer__strategy': 'mean',\n",
       " 'columntransformer__pipeline-2__standardscaler': MinMaxScaler(copy=True, feature_range=(0, 1)),\n",
       " 'logisticregression__C': 1.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_test, y_test).best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "Do the following exercise:\n",
    "\n",
    "Load the adult dataset located in `./data/adult_openml.csv`. Make your own `ColumnTransformer` preprocessor. Pipeline it with a classifier. Fine tune it and check the prediction accuracy within a cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Read the adult dataset located in `./data/adult_openml.csv` using `pd.read_csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data2 = pd.read_csv(os.path.join('data', 'adult_openml.csv'))\n",
    "data2 = pd.read_csv(r\"adult_openml.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capitalgain</th>\n",
       "      <th>capitalloss</th>\n",
       "      <th>hoursperweek</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education-num  \\\n",
       "0    2         State-gov   77516  Bachelors             13   \n",
       "1    3  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2    2           Private  215646    HS-grad              9   \n",
       "3    3           Private  234721       11th              7   \n",
       "4    1           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capitalgain  capitalloss  hoursperweek native-country  class  \n",
       "0            1            0             2  United-States  <=50K  \n",
       "1            0            0             0  United-States  <=50K  \n",
       "2            0            0             2  United-States  <=50K  \n",
       "3            0            0             2  United-States  <=50K  \n",
       "4            0            0             2           Cuba  <=50K  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split the datasets into a data and a target. The target corresponds to the `class` column. For the data, drop the columns `fnlwgt`, `capitalgain`, and `capitalloss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data2['class']\n",
    "data = data2.drop(columns=['class', 'fnlwgt', 'capitalgain', 'capitalloss'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The target is not encoded. Use the `sklearn.preprocessing.LabelEncoder` to encode the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "target = LabelEncoder().fit_transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, stratify = target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a list containing the name of the categorical columns. Similarly, do the same for the numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_cat = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'native-country', 'sex']\n",
    "col_num = ['age', 'hoursperweek']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a pipeline to one-hot encode the categorical data. Use the `KBinsDiscretizer` for the numerical data. Import it from `sklearn.preprocessing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "pipe_cat = OneHotEncoder(handle_unknown='ignore')\n",
    "pipe_num = KBinsDiscretizer(strategy = 'uniform')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a `preprocessor` by using the `make_column_transformer`. You should apply the right pipeline to the right column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "preprocessor = make_column_transformer((pipe_cat, col_cat), (pipe_num, col_num))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pipeline the preprocessor with a `LogisticRegression` classifier. Subsequently define a grid-search to find the best parameter `C`. Train and test this workflow in a cross-validation scheme using `cross_validate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1444b2f93c8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pipe = make_pipeline(preprocessor, LogisticRegression(solver='lbfgs', max_iter=1000))\n",
    "\n",
    "param_grid = {'logisticregression__C': [0.1, 1.0, 10]}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "scores = pd.DataFrame(cross_validate(grid, data, target, scoring='balanced_accuracy', cv=3, n_jobs=-1, return_train_score=True))\n",
    "scores[['train_score', 'test_score']].boxplot(whis=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Estimatior(SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(preprocessor, SVC())\n",
    "\n",
    "param_grid = {'svc__C': [0.1, 1,10]\n",
    "              #'svc__gamma': [0.1, 1, 10]\n",
    "             }\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Behnam\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:197: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.83899762509213"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
